{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Neither', 'DT'), ('Lorillard', 'NNP'), ('nor', 'CC'), ('the', 'DT'), ('researchers', 'NNS'), ('who', 'WP'), ('*T*-3', '-NONE-'), ('studied', 'VBD'), ('the', 'DT'), ('workers', 'NNS'), ('were', 'VBD'), ('aware', 'JJ'), ('of', 'IN'), ('any', 'DT'), ('research', 'NN'), ('on', 'IN'), ('smokers', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Kent', 'NNP'), ('cigarettes', 'NNS'), ('.', '.')]\n",
      "[('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "[('Joe', 'NNP'), ('met', 'VBD'), ('Joanne', 'NNP'), ('in', 'IN'), ('Lahore', 'NNP'), ('.', 'NNP')]\n",
      "[('Chicago', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('birthplace', 'NNP'), ('of', 'NNP'), ('Ginny', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# Train data - pretagged\n",
    "train_data = treebank.tagged_sents()[:3000]\n",
    "\n",
    "print (train_data[10])\n",
    "\n",
    "# Import HMM module\n",
    "from nltk.tag import hmm\n",
    "\n",
    "# Setup a trainer with default(None) values\n",
    "# And train with the data\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_data)\n",
    "\n",
    "#print (tagger)\n",
    "# Prints the basic data about the tagger\n",
    "\n",
    "tags = tagger.tag(\"Today is a good day .\".split())\n",
    "print(tags)\n",
    "\n",
    "tags = tagger.tag(\"Joe met Joanne in Lahore .\".split())\n",
    "print(tags)\n",
    "tags = tagger.tag(\"Chicago is the birthplace of Ginny\".split())\n",
    "print(tags)\n",
    "\n",
    "#import numpy as np\n",
    "#myarray = np.fromfile('ECG-Ali.dat')\n",
    "#print(myarray)\n",
    "\n",
    "#print \"Here's your file %r:\" % filename\n",
    "#print txt.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demo_pos():\n",
    "    # demonstrates POS tagging using supervised training\n",
    " \n",
    "    print()\n",
    "    print('HMM POS tagging demo')\n",
    "    print()\n",
    " \n",
    "    print('Training HMM...')\n",
    "    labelled_sequences, tag_set, symbols = load_pos(20000)\n",
    "    trainer = HiddenMarkovModelTrainer(tag_set, symbols)\n",
    "    hmm = trainer.train_supervised(labelled_sequences[10:],\n",
    "    estimator=lambda fd, bins: LidstoneProbDist(fd, 0.1, bins))\n",
    " \n",
    "    print('Testing...')\n",
    "    hmm.test(labelled_sequences[:10], verbose=True)\n",
    " \n",
    "def load_pos(num_sents):\n",
    "    from nltk.corpus import brown\n",
    " \n",
    "    sentences = brown.tagged_sents(categories='news')[:num_sents]\n",
    " \n",
    "    tag_re = re.compile(r'[*]|--|[^+*-]+')\n",
    "    tag_set = set()\n",
    "    symbols = set()\n",
    " \n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            word, tag = sentence[i]\n",
    "            word = word.lower() # normalize\n",
    "            symbols.add(word) # log this word\n",
    "            # Clean up the tag.\n",
    "            tag = tag_re.match(tag).group()\n",
    "            tag_set.add(tag)\n",
    "            sentence[i] = (word, tag) # store cleaned-up tagged token\n",
    "        cleaned_sentences += [sentence]\n",
    " \n",
    "    return cleaned_sentences, list(tag_set), list(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
